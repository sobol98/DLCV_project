{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":25563,"databundleVersionId":2094376,"sourceType":"competition"},{"sourceId":2032065,"sourceType":"datasetVersion","datasetId":1216613},{"sourceId":63374,"sourceType":"modelInstanceVersion","modelInstanceId":52841}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision import transforms\nfrom torchvision import models as models\nimport torchvision\nfrom torch.utils.data import random_split  \nimport torch\nimport torch.nn as nn\n\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\nimport albumentations as A # Image augmentation\nfrom albumentations.pytorch import ToTensorV2 # Image Augmentation\n\nfrom tqdm.notebook import tqdm\n\nprint(\"import done\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-09T18:10:09.509849Z","iopub.execute_input":"2024-06-09T18:10:09.510480Z","iopub.status.idle":"2024-06-09T18:10:21.192897Z","shell.execute_reply.started":"2024-06-09T18:10:09.510447Z","shell.execute_reply":"2024-06-09T18:10:21.191938Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"import done\n","output_type":"stream"}]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'  \nprint(\"device:\",device)\n\nclass_threshold = 0.4\n\nnum_epochs = 30\nbatch_size = 256\nlr = 0.0001\nimg_size = 256  ","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.195062Z","iopub.execute_input":"2024-06-09T18:10:21.195872Z","iopub.status.idle":"2024-06-09T18:10:21.256700Z","shell.execute_reply.started":"2024-06-09T18:10:21.195825Z","shell.execute_reply":"2024-06-09T18:10:21.255687Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# 1. Processing the Dataset\nresize_img_file = '../input/resized-plant2021/img_sz_256'\n# train_img_file=\"../input/plant-pathology-2021-fgvc8/train_images/\"\ntest_img_dir =  '../input/plant-pathology-2021-fgvc8/test_images/'\ntrain_origin = pd.read_csv('../input/plant-pathology-2021-fgvc8/train.csv')\n\ntrain_origin.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.258019Z","iopub.execute_input":"2024-06-09T18:10:21.258366Z","iopub.status.idle":"2024-06-09T18:10:21.335721Z","shell.execute_reply.started":"2024-06-09T18:10:21.258339Z","shell.execute_reply":"2024-06-09T18:10:21.334749Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                  image                           labels\n0  800113bb65efe69e.jpg                          healthy\n1  8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex\n2  80070f7fb5e2ccaa.jpg                             scab\n3  80077517781fb94f.jpg                             scab\n4  800cbf0ff87721f8.jpg                          complex","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800113bb65efe69e.jpg</td>\n      <td>healthy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002cb321f8bfcdf.jpg</td>\n      <td>scab frog_eye_leaf_spot complex</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80070f7fb5e2ccaa.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>scab</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800cbf0ff87721f8.jpg</td>\n      <td>complex</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#smaller dataset\n# train_origin = train_origin.sample(frac=0.4, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.338826Z","iopub.execute_input":"2024-06-09T18:10:21.339228Z","iopub.status.idle":"2024-06-09T18:10:21.343067Z","shell.execute_reply.started":"2024-06-09T18:10:21.339193Z","shell.execute_reply":"2024-06-09T18:10:21.342132Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# 2. Initialize multi-label labels using one-hot encoding\nlabels_list = [\"healthy\", \"scab\", \"rust\", \"frog_eye_leaf_spot\", \"powdery_mildew\", \"complex\"]\ntrain_df = train_origin[['image']].copy()\nfor label in labels_list:\n    train_df[label] = 0\n\nfor label in labels_list:\n    train_df.loc[train_origin['labels'].str.contains(label), label] = 1\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.344200Z","iopub.execute_input":"2024-06-09T18:10:21.344440Z","iopub.status.idle":"2024-06-09T18:10:21.429252Z","shell.execute_reply.started":"2024-06-09T18:10:21.344419Z","shell.execute_reply":"2024-06-09T18:10:21.428397Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                  image  healthy  scab  rust  frog_eye_leaf_spot  \\\n0  800113bb65efe69e.jpg        1     0     0                   0   \n1  8002cb321f8bfcdf.jpg        0     1     0                   1   \n2  80070f7fb5e2ccaa.jpg        0     1     0                   0   \n3  80077517781fb94f.jpg        0     1     0                   0   \n4  800cbf0ff87721f8.jpg        0     0     0                   0   \n\n   powdery_mildew  complex  \n0               0        0  \n1               0        1  \n2               0        0  \n3               0        0  \n4               0        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>healthy</th>\n      <th>scab</th>\n      <th>rust</th>\n      <th>frog_eye_leaf_spot</th>\n      <th>powdery_mildew</th>\n      <th>complex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800113bb65efe69e.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8002cb321f8bfcdf.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>80070f7fb5e2ccaa.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>80077517781fb94f.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>800cbf0ff87721f8.jpg</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class PathologyPlantsDataset(Dataset): # Load image\n    def __init__(self, image_ids, targets, path, mode, transform=None):\n        self.image_ids = image_ids\n        self.targets = targets\n        self.root_dir = path\n        self.mode = mode\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, idx):\n        # Read image\n        image_path = os.path.join(self.root_dir, self.image_ids.iloc[idx])\n        image = Image.open(image_path)\n        img = np.array(image)\n        # Process image\n        if self.transform:\n            image = self.transform(image=img)['image']\n        \n        if self.mode == 'test':\n            target = None\n        else:\n            target = torch.tensor(self.targets[idx], dtype=torch.float32) \n        \n        return (image, target)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.430323Z","iopub.execute_input":"2024-06-09T18:10:21.430615Z","iopub.status.idle":"2024-06-09T18:10:21.439102Z","shell.execute_reply.started":"2024-06-09T18:10:21.430591Z","shell.execute_reply":"2024-06-09T18:10:21.438070Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n#     A.Rotate(\n#         always_apply=False, \n#         p=0.1, \n#         limit=(-68, 178), \n#         interpolation=1, \n#         border_mode=0, \n#         value=(0, 0, 0), \n#         mask_value=None\n#     ),\n#     A.RandomShadow(\n#         num_shadows_lower=1, \n#         num_shadows_upper=1, \n#         shadow_dimension=3, \n#         shadow_roi=(0, 0.6, 1, 1), \n#         p=0.4\n#     ),\n#     A.ShiftScaleRotate(\n#         shift_limit=0.05, \n#         scale_limit=0.05, \n#         rotate_limit=15, \n#         p=0.6\n#     ),\n#     A.RandomFog(\n#         fog_coef_lower=0.2, \n#         fog_coef_upper=0.2, \n#         alpha_coef=0.2, \n#         p=0.3\n#     ),\n#     A.RGBShift(\n#         r_shift_limit=15, \n#         g_shift_limit=15, \n#         b_shift_limit=15, \n#         p=0.3\n#     ),\n#     A.RandomBrightnessContrast(\n#         p=0.3\n#     ),\n#     A.GaussNoise(\n#         var_limit=(50, 70),  \n#         always_apply=False, \n#         p=0.3\n#     ),\n    A.Resize(\n        height=img_size,\n        width=img_size,\n    ),\n#     A.CoarseDropout(\n#         max_holes=5, \n#         max_height=5, \n#         max_width=5, \n#         min_holes=3, \n#         min_height=5, \n#         min_width=5,\n#         always_apply=False, \n#         p=0.2\n#     ),\n#     A.Normalize(\n#         mean=(0.485, 0.456, 0.406), \n#         std=(0.229, 0.224, 0.225)\n#     ),\n    ToTensorV2(),\n])\nval_transform = A.Compose([\n    A.Resize(\n        height=img_size,\n        width=img_size,\n    ),\n#     A.Normalize(\n#         mean=(0.485, 0.456, 0.406), \n#         std=(0.229, 0.224, 0.225)\n#     ),\n    ToTensorV2(),\n])\n\n\nX_train, X_valid, y_train, y_valid = train_test_split(\n    train_df['image'], \n    train_df[labels_list].values,  \n    test_size=0.2, \n    random_state=42\n)\nprint(\"Training dataset length：\",len(X_train))\nprint(\"Testing dataset length：\",len(X_valid))\n\nfor i in range(2):  # Print the first 2 samples for inspection\n    print(f\"Image path: {X_train.iloc[i]}, Labels: {y_train[i]}\") ","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.440752Z","iopub.execute_input":"2024-06-09T18:10:21.441058Z","iopub.status.idle":"2024-06-09T18:10:21.469168Z","shell.execute_reply.started":"2024-06-09T18:10:21.441033Z","shell.execute_reply":"2024-06-09T18:10:21.468297Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training dataset length： 14905\nTesting dataset length： 3727\nImage path: a77c35e0f885c03b.jpg, Labels: [0 0 0 0 0 1]\nImage path: 9fbb71e598132988.jpg, Labels: [0 0 1 0 0 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_set = PathologyPlantsDataset(X_train, y_train, path=resize_img_file ,mode='train',transform=train_transform)\nval_set = PathologyPlantsDataset(X_valid, y_valid, path=resize_img_file, mode='valid', transform=val_transform)\n# train_set = PathologyPlantsDataset(X_train, y_train, path=train_img_file ,mode='train',transform=train_transform)\n# val_set = PathologyPlantsDataset(X_valid, y_valid, path=train_img_file, mode='valid', transform=val_transform)\n\n# Hyperparameter settings\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.470380Z","iopub.execute_input":"2024-06-09T18:10:21.470680Z","iopub.status.idle":"2024-06-09T18:10:21.476733Z","shell.execute_reply.started":"2024-06-09T18:10:21.470655Z","shell.execute_reply":"2024-06-09T18:10:21.475774Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def model_resnet():\n    # Load pre-trained ResNet50 model\n#     model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n    model = models.resnet50()\n    \n    \n    # Unfreeze the parameters of all layers (if you need to fine-tune the whole model, you can comment out this code below)\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Modify the last layer of the model\n    model.fc = nn.Sequential(\n        nn.Linear(model.fc.in_features,512),\n        nn.ReLU(),  # ReLU activation function\n        nn.BatchNorm1d(512),  # approved standardized layer\n        nn.Dropout(0.5),\n        nn.Linear(512, 6),  # The final fully connected layer that maps feature dimensions to category numbers\n        nn.Sigmoid()  # Sigmoid Activation function for multi-label categorization\n    )\n    # Załaduj model bezpośrednio z lokalizacji pliku\n    model_path='/kaggle/input/resnet50/pytorch/base/1/my_resnet_model.pth'\n    model.load_state_dict(torch.load(model_path))\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.477917Z","iopub.execute_input":"2024-06-09T18:10:21.478177Z","iopub.status.idle":"2024-06-09T18:10:21.495234Z","shell.execute_reply.started":"2024-06-09T18:10:21.478155Z","shell.execute_reply":"2024-06-09T18:10:21.494453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"my_resnet = model_resnet().to(device)\n# loss_fn = torch.nn.MultiLabelSoftMarginLoss()\nloss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(my_resnet.parameters(), lr=lr)\n\n\nmy_resnet = nn.DataParallel(my_resnet)  #use 2x GPU (it's faster)\n# model = model.to(device)\n# Zapisanie modelu na dysku\n# torch.save(my_resnet.state_dict(), model_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:21.498386Z","iopub.execute_input":"2024-06-09T18:10:21.498735Z","iopub.status.idle":"2024-06-09T18:10:23.649751Z","shell.execute_reply.started":"2024-06-09T18:10:21.498711Z","shell.execute_reply":"2024-06-09T18:10:23.648700Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\nfrom tqdm import tqdm\n\ndef to_numpy(tensor):\n    return tensor.detach().cpu().numpy()\n\ndef get_metrics(y_pred_proba,y_test,threshold=0.5):\n    y_pred = np.where(y_pred_proba > threshold, 1, 0)\n    y1 = y_pred.round().astype(np.float32)\n    y2 = y_test.round().astype(np.float32)\n    \n    \n    y_pred = (y_pred_proba > threshold).astype(int)  # Direct conversion to integer  \n    f1 = f1_score(y_test, y_pred, average='samples', zero_division=1)\n    acc = accuracy_score(y_test,y_pred, normalize=True)\n\n    return acc, f1 \n\ndef train_or_valid(dataloader, model, device, loss_fn, optimizer=None, is_train=True):\n    torch.cuda.empty_cache()\n    loss_val = 0\n    accuracy = 0\n    f1score = 0\n    num_batches = len(dataloader)\n    \n    if is_train:\n        model.train()\n    else:\n        model.eval()\n    \n    with torch.set_grad_enabled(is_train):\n        stream = tqdm(dataloader)\n        for batch, (X, y) in enumerate(stream, start=1):\n            X, y = X.to(device).float(), y.to(device)\n            \n            pred_prob = model(X)\n            loss = loss_fn(pred_prob, y)\n            \n            if is_train:\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            \n            loss_val += loss.item()\n            acc, f1 = get_metrics(to_numpy(pred_prob), to_numpy(y))\n            \n            accuracy += acc\n            f1score += f1\n            \n            desc = f'Epoch {epoch:3d}/{num_epochs} - {\"train\" if is_train else \"valid\"}_Loss: {loss_val/batch:.4f}, ' + \\\n                   f'{\"train\" if is_train else \"valid\"}_Acc: {accuracy/batch:.4f}, {\"train\" if is_train else \"valid\"}_F1: {f1score/batch:.4f}'\n            stream.set_description(desc)\n    \n    return loss_val / num_batches, accuracy / num_batches, f1score / num_batches\n\ndef train(dataloader, model, device, loss_fn, optimizer, train_loss, train_acc, train_f1, epoch, num_epochs):\n    loss, acc, f1 = train_or_valid(dataloader, model, device, loss_fn, optimizer, is_train=True)\n    train_loss.append(loss)\n    train_acc.append(acc)\n    train_f1.append(f1)\n\ndef valid(dataloader, model, device, loss_fn, valid_loss, valid_acc, valid_f1, epoch, num_epochs):\n    loss, acc, f1 = train_or_valid(dataloader, model, device, loss_fn, optimizer=None, is_train=False)\n    valid_loss.append(loss)\n    valid_acc.append(acc)\n    valid_f1.append(f1)\n    return f1\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:23.653494Z","iopub.execute_input":"2024-06-09T18:10:23.653811Z","iopub.status.idle":"2024-06-09T18:10:23.668994Z","shell.execute_reply.started":"2024-06-09T18:10:23.653787Z","shell.execute_reply":"2024-06-09T18:10:23.668151Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"%%time\n# training process\n\ntrain_loss, train_acc, train_f1 = [], [], []\nvalid_loss, valid_acc, valid_f1 = [], [], []\n\nbest_f1 = 0\nfor epoch in range(1, num_epochs + 1):\n    train(train_loader, my_resnet, device, loss_fn, optimizer, train_loss, train_acc, train_f1, epoch, num_epochs)\n    vaild_f1 = valid(valid_loader, my_resnet, device, loss_fn, valid_loss, valid_acc, valid_f1, epoch, num_epochs)\n    if vaild_f1 > best_f1:\n        torch.save(my_resnet.state_dict(),'Best_model.pth')\n        best_f1 = vaild_f1","metadata":{"execution":{"iopub.status.busy":"2024-06-09T18:10:23.670114Z","iopub.execute_input":"2024-06-09T18:10:23.670382Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch   1/30 - train_Loss: 0.8507, train_Acc: 0.0534, train_F1: 0.4370: 100%|██████████| 59/59 [02:42<00:00,  2.76s/it]\nEpoch   1/30 - valid_Loss: 0.8364, valid_Acc: 0.0794, valid_F1: 0.5155: 100%|██████████| 15/15 [00:37<00:00,  2.53s/it]\nEpoch   2/30 - train_Loss: 0.8174, train_Acc: 0.1235, train_F1: 0.5433: 100%|██████████| 59/59 [01:03<00:00,  1.08s/it]\nEpoch   2/30 - valid_Loss: 0.8010, valid_Acc: 0.1789, valid_F1: 0.5883: 100%|██████████| 15/15 [00:15<00:00,  1.03s/it]\nEpoch   3/30 - train_Loss: 0.7996, train_Acc: 0.1770, train_F1: 0.5847: 100%|██████████| 59/59 [01:03<00:00,  1.08s/it]\nEpoch   3/30 - valid_Loss: 0.7845, valid_Acc: 0.2389, valid_F1: 0.6227: 100%|██████████| 15/15 [00:15<00:00,  1.00s/it]\nEpoch   4/30 - train_Loss: 0.7839, train_Acc: 0.2395, train_F1: 0.6227: 100%|██████████| 59/59 [01:03<00:00,  1.07s/it]\nEpoch   4/30 - valid_Loss: 0.7748, valid_Acc: 0.2769, valid_F1: 0.6403: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it]\nEpoch   5/30 - train_Loss: 0.7737, train_Acc: 0.2784, train_F1: 0.6430:  51%|█████     | 30/59 [00:32<00:30,  1.05s/it]","output_type":"stream"}]},{"cell_type":"code","source":"from matplotlib.ticker import MaxNLocator \n\ndef plot_result(train,valid,mode,file_name):\n    epochs = range(1, len(train) + 1)\n    fig, ax = plt.subplots(figsize=(8, 5)) \n    if mode == 'loss':\n        ax.plot(epochs, train, label='Training loss', marker='o')  \n        ax.plot(epochs, valid, label='Validation loss', marker='o')  \n        ax.legend(frameon=False, fontsize=14)  \n        ax.get_xaxis().set_major_locator(MaxNLocator(integer=True))  \n        ax.set_title('Loss', fontsize=18)  \n        ax.set_xlabel('Epoch', fontsize=14)  \n        ax.set_ylabel('Loss', fontsize=14)  \n        plt.savefig(file_name + '.png')\n#         plt.close(fig)\n    elif mode == 'acc':\n        ax.plot(epochs, train, label='Training Accuracy', marker='o')  \n        ax.plot(epochs, valid, label='Validation accuracy', marker='o')  \n        ax.legend(frameon=False, fontsize=14)  \n        ax.get_xaxis().set_major_locator(MaxNLocator(integer=True))  \n        ax.set_title('Accuracy', fontsize=18)  \n        ax.set_xlabel('Epoch', fontsize=14)  \n        ax.set_ylabel('Accuracy', fontsize=14)  \n        plt.savefig(file_name + '.png')\n#         plt.close(fig)\n    elif mode =='f1':\n        ax.plot(epochs, train, label='Training F1-Score', marker='o')  \n        ax.plot(epochs, valid, label='Validation F1-Score', marker='o')  \n        ax.legend(frameon=False, fontsize=14)  \n        ax.get_xaxis().set_major_locator(MaxNLocator(integer=True))  \n        ax.set_title('F1-Score', fontsize=18)  \n        ax.set_xlabel('Epoch', fontsize=14)  \n        ax.set_ylabel('F1-Score', fontsize=14)  \n        plt.savefig(file_name + '.png')\n#         plt.close(fig)\n                ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_result(train_loss,valid_loss,'loss','res_loss')    \nplot_result(train_acc,valid_acc,'acc','res_acc')  \nplot_result(train_f1,valid_f1,'f1','res_f1')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n# Define test image directory\ntest_img_dir = '../input/plant-pathology-2021-fgvc8/test_images'\n\n# Define transformation for test images\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Assuming the model expects input size of 224x224\n    transforms.ToTensor(),\n])\n\n# Custom dataset class for the test images\nclass TestDataset(Dataset):\n    def __init__(self, img_dir, transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.img_filenames = os.listdir(img_dir)\n\n    def __len__(self):\n        return len(self.img_filenames)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_filenames[idx])\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, self.img_filenames[idx]\n\n# Create DataLoader for the test dataset\ntest_dataset = TestDataset(test_img_dir, transform=test_transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Load the best model\nmodel_path = 'Best_model.pth'\nmy_resnet.load_state_dict(torch.load(model_path))\nmy_resnet.to(device)\n\n#-----------------------------------------------------------------------\n\n# Function to run inference on the test set and generate predictions\ndef test(dataloader, model, device):\n    model.eval()\n    predictions = []\n    filenames = []\n    \n    with torch.no_grad():\n        stream = tqdm(dataloader, desc=\"Testing\")\n        for X, filenames_batch in stream:\n            X = X.to(device)\n            pred_proba = model(X)\n            y_pred = torch.sigmoid(pred_proba)  # Assuming sigmoid for binary/multilabel classification\n            y_pred = (y_pred > 0.5).int()  # Apply threshold\n\n            predictions.extend(y_pred.cpu().numpy())\n            filenames.extend(filenames_batch)\n    \n    return predictions, filenames\n\n# Run the test function with the DataLoader\ntest_predictions, test_filenames = test(test_loader, my_resnet, device)\n# mapped_predictions = map_predictions(test_predictions, 0.5) #ssdsds\n\n\n# Convert predictions to labels\nmapped_predictions = []\nfor pred in test_predictions:\n    classes = [labels_list[i] for i, val in enumerate(pred) if val == 1]\n    mapped_pred = ' '.join(classes)\n    mapped_predictions.append(mapped_pred)\n    \n    \n# Prepare the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'image': test_filenames,\n    'labels': mapped_predictions\n})\n\n# Save the submission file\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T16:35:14.042347Z","iopub.execute_input":"2024-06-09T16:35:14.042955Z","iopub.status.idle":"2024-06-09T16:35:15.012990Z","shell.execute_reply.started":"2024-06-09T16:35:14.042921Z","shell.execute_reply":"2024-06-09T16:35:15.012046Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Testing: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Submission file saved as 'submission.csv'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Read the submission CSV file\nsubmission_df = pd.read_csv('submission.csv')\n\n# Print the contents of the submission DataFrame\nprint(\"Submission DataFrame:\")\nprint(submission_df)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T16:35:18.520487Z","iopub.execute_input":"2024-06-09T16:35:18.521316Z","iopub.status.idle":"2024-06-09T16:35:18.530626Z","shell.execute_reply.started":"2024-06-09T16:35:18.521284Z","shell.execute_reply":"2024-06-09T16:35:18.529584Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Submission DataFrame:\n                  image   labels\n0  ad8770db05586b59.jpg  healthy\n1  c7b03e718489f3ca.jpg  healthy\n2  85f8cb619c66b863.jpg  healthy\n","output_type":"stream"}]},{"cell_type":"code","source":"# import torch\n# from torchvision import transforms\n# from PIL import Image\n\n# # Define test image path\n# test_img_path = '../input/plant-pathology-2021-fgvc8/train_images/800113bb65efe69e.jpg'\n\n# # Define transformation for the test image\n# test_transform = transforms.Compose([\n#     transforms.Resize((224, 224)),  # Assuming the model expects input size of 224x224\n#     transforms.ToTensor(),\n# ])\n\n# # Load the test image\n# test_image = Image.open(test_img_path).convert('RGB')\n# test_image = test_transform(test_image).unsqueeze(0)  # Add batch dimension\n\n# # Load the best model\n# model_path = 'Best_model.pth'\n# my_resnet.load_state_dict(torch.load(model_path))\n# my_resnet.to(device)\n\n# # Put the model in evaluation mode\n# my_resnet.eval()\n\n# # Move the test image to the appropriate device\n# test_image = test_image.to(device)\n\n# # Perform inference\n# with torch.no_grad():\n#     pred_proba = my_resnet(test_image)\n#     pred_label = torch.sigmoid(pred_proba) > 0.5\n\n# # Convert prediction to label\n# labels_list = [\"healthy\", \"scab\", \"rust\", \"frog_eye_leaf_spot\", \"powdery_mildew\", \"complex\"]\n# predicted_labels = [labels_list[i] for i, val in enumerate(pred_label.squeeze().tolist()) if val == 1]\n\n# # Print predicted labels\n# print(\"Predicted labels:\", predicted_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-09T10:02:40.235551Z","iopub.execute_input":"2024-06-09T10:02:40.236369Z","iopub.status.idle":"2024-06-09T10:02:40.245261Z","shell.execute_reply.started":"2024-06-09T10:02:40.236339Z","shell.execute_reply":"2024-06-09T10:02:40.244439Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# test_image_path = '../input/plant-pathology-2021-fgvc8/test_images/'\n\n# test_images = os.listdir(test_image_path)\n\n# os.listdir(\"/kaggle/working\")\n# if os.path.exists(\"/kaggle/working/submission.csv\"):\n#     os.remove(\"submission.csv\")\n\n\n\n# sub = pd.DataFrame(test_images, columns=['image'])\n# sub['labels'] = 'frog_eye_leaf_spot'\n# sub['labels'] = 'rust'\n# print(sub)\n# print(len(sub))","metadata":{"execution":{"iopub.status.busy":"2024-06-09T10:29:37.381435Z","iopub.execute_input":"2024-06-09T10:29:37.382099Z","iopub.status.idle":"2024-06-09T10:29:37.393185Z","shell.execute_reply.started":"2024-06-09T10:29:37.382068Z","shell.execute_reply":"2024-06-09T10:29:37.392245Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"                  image labels\n0  ad8770db05586b59.jpg   rust\n1  c7b03e718489f3ca.jpg   rust\n2  85f8cb619c66b863.jpg   rust\n3\n","output_type":"stream"}]},{"cell_type":"code","source":"# sub.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-09T10:29:40.688359Z","iopub.execute_input":"2024-06-09T10:29:40.689165Z","iopub.status.idle":"2024-06-09T10:29:40.694310Z","shell.execute_reply.started":"2024-06-09T10:29:40.689136Z","shell.execute_reply":"2024-06-09T10:29:40.693390Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}